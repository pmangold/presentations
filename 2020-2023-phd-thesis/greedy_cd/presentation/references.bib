@article{bassily2014Differentially,
  title = {Differentially {{Private Empirical Risk Minimization}}: {{Efficient Algorithms}} and {{Tight Error Bounds}}},
  shorttitle = {Differentially {{Private Empirical Risk Minimization}}},
  author = {Bassily, Raef and Smith, Adam and Thakurta, Abhradeep},
  year = {2014},
  month = oct,
  journal = {arXiv:1405.7085 [cs, stat]},
  eprint = {1405.7085},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  url = {http://arxiv.org/abs/1405.7085},
  urldate = {2021-09-07},
  abstract = {In this paper, we initiate a systematic investigation of differentially private algorithms for convex empirical risk minimization. Various instantiations of this problem have been studied before. We provide new algorithms and matching lower bounds for private ERM assuming only that each data point's contribution to the loss function is Lipschitz bounded and that the domain of optimization is bounded. We provide a separate set of algorithms and matching lower bounds for the setting in which the loss functions are known to also be strongly convex.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/pmangold/research/references/pdf/bassily_et_al_2014_differentially_private_empirical_risk_minimization3.pdf}
}

@article{chaudhuri2011Differentially,
  title = {Differentially {{Private Empirical Risk Minimization}}},
  author = {Chaudhuri, Kamalika and Monteleoni, Claire and Sarwate, Anand D.},
  year = {2011},
  journal = {Journal of Machine Learning Research},
  volume = {12},
  number = {29},
  pages = {1069--1109},
  issn = {1533-7928},
  url = {http://jmlr.org/papers/v12/chaudhuri11a.html},
  urldate = {2021-06-29},
  file = {/home/pmangold/research/references/pdf/chaudhuri_et_al_2011_differentially_private_empirical_risk_minimization2.pdf;/home/pmangold/zotero/storage/67E5FYTK/chaudhuri11a.html}
}

@inproceedings{dwork2006Differential,
  title = {Differential {{Privacy}}},
  booktitle = {Automata, {{Languages}} and {{Programming}}},
  author = {Dwork, Cynthia},
  editor = {Bugliesi, Michele and Preneel, Bart and Sassone, Vladimiro and Wegener, Ingo},
  year = {2006},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {1--12},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/11787006_1},
  url = {https://link.springer.com/chapter/10.1007%2F11787006_1},
  abstract = {In 1977 Dalenius articulated a desideratum for statistical databases: nothing about an individual should be learnable from the database that cannot be learned without access to the database. We give a general impossibility result showing that a formalization of Dalenius' goal along the lines of semantic security cannot be achieved. Contrary to intuition, a variant of the result threatens the privacy even of someone not in the database. This state of affairs suggests a new measure, differential privacy, which, intuitively, captures the increased risk to one's privacy incurred by participating in a database. The techniques developed in a sequence of papers [8, 13, 3], culminating in those described in [12], can achieve any desired level of privacy under this measure. In many cases, extremely accurate information about the database can be provided while simultaneously ensuring very high levels of privacy.},
  isbn = {978-3-540-35908-1},
  langid = {english},
  keywords = {Auxiliary Information,Differential Privacy,Impossibility Result,Statistical Database,Turing Machine},
  file = {/home/pmangold/research/references/pdf/dwork_2006_differential_privacy.pdf;/home/pmangold/research/references/pdf/dwork_2006_differential_privacy2.pdf}
}

@article{mangold2021Differentially,
  title = {Differentially {{Private Coordinate Descent}} for {{Composite Empirical Risk Minimization}}},
  author = {Mangold, Paul and Bellet, Aur{\'e}lien and Salmon, Joseph and Tommasi, Marc},
  year = {2021},
  month = oct,
  journal = {arXiv:2110.11688 [cs, stat]},
  eprint = {2110.11688},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  url = {http://arxiv.org/abs/2110.11688},
  urldate = {2021-11-05},
  abstract = {Machine learning models can leak information about the data used to train them. Differentially Private (DP) variants of optimization algorithms like Stochastic Gradient Descent (DP-SGD) have been designed to mitigate this, inducing a trade-off between privacy and utility. In this paper, we propose a new method for composite Differentially Private Empirical Risk Minimization (DP-ERM): Differentially Private proximal Coordinate Descent (DP-CD). We analyze its utility through a novel theoretical analysis of inexact coordinate descent, and highlight some regimes where DP-CD outperforms DP-SGD, thanks to the possibility of using larger step sizes. We also prove new lower bounds for composite DP-ERM under coordinate-wise regularity assumptions, that are, in some settings, nearly matched by our algorithm. In practical implementations, the coordinate-wise nature of DP-CD updates demands special care in choosing the clipping thresholds used to bound individual contributions to the gradients. A natural parameterization of these thresholds emerges from our theory, limiting the addition of unnecessarily large noise without requiring coordinate-wise hyperparameter tuning or extra computational cost.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/pmangold/research/references/pdf/mangold_et_al_2021_differentially_private_coordinate_descent_for_composite_empirical_risk.pdf;/home/pmangold/zotero/storage/N6XB8DFW/2110.html}
}

@article{richtarik2014Iteration,
  title = {Iteration Complexity of Randomized Block-Coordinate Descent Methods for Minimizing a Composite Function},
  author = {Richt{\'a}rik, Peter and Tak{\'a}{\v c}, Martin},
  year = {2014},
  month = apr,
  journal = {Mathematical Programming},
  volume = {144},
  number = {1-2},
  pages = {1--38},
  issn = {0025-5610, 1436-4646},
  doi = {10.1007/s10107-012-0614-z},
  url = {http://link.springer.com/10.1007/s10107-012-0614-z},
  urldate = {2019-10-22},
  abstract = {In this paper we develop a randomized block-coordinate descent method for minimizing the sum of a smooth and a simple nonsmooth block-separable convex function and prove that it obtains an {$\epsilon$}-accurate solution with probability at least 1 - {$\rho$} in at most O((n/{$\epsilon$}) log(1/{$\rho$})) iterations, where n is the number of blocks. This extends recent results of Nesterov [Efficiency of coordinate descent methods on huge-scale optimization problems, SIAM J Optimization 22(2), pp. 341\textendash 362, 2012], which cover the smooth case, to composite minimization, while at the same time improving the complexity by the factor of 4 and removing {$\epsilon$} from the logarithmic term. More importantly, in contrast with the aforementioned work in which the author achieves the results by applying the method to a regularized version of the objective function with an unknown scaling factor, we show that this is not necessary, thus achieving first true iteration complexity bounds. For strongly convex functions the method converges linearly. In the smooth case we also allow for arbitrary probability vectors and non-Euclidean norms. Finally, we demonstrate numerically that the algorithm is able to solve huge-scale {$\mathscr{l}$}1-regularized least squares with a billion variables.},
  langid = {english},
  keywords = {favorite},
  file = {/home/pmangold/research/references/pdf/richtárik_takáč_2014_iteration_complexity_of_randomized_block-coordinate_descent_methods_for.pdf}
}