@article{shokri_membership_2017,
  title={Membership inference attacks against machine learning models},
  author={Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly},
  journal={2017 IEEE Symposium on Security and Privacy (SP)},
  pages={3--18},
  year={2017},
  organization={IEEE}
}

@article{geiping_inverting_2020,
  title={Inverting Gradients--How easy is it to break privacy in federated learning?},
  author={Geiping, Jonas and Bauermeister, Hartmut and Dr{\"o}ge, Hannah and Moeller, Michael},
  journal={arXiv preprint arXiv:2003.14053},
  year=2020
}

@article{dwork_algorithmic_2014,
  title={The algorithmic foundations of differential privacy.},
  author={Dwork, Cynthia and Roth, Aaron and others},
  journal={Foundations and Trends in Theoretical Computer Science},
  volume={9},
  number={3-4},
  pages={211--407},
  year={2014}
}

@article{chaudhuri_differentially_2011,
  title={Differentially private empirical risk minimization.},
  author={Chaudhuri, Kamalika and Monteleoni, Claire and Sarwate, Anand D},
  journal={Journal of Machine Learning Research},
  volume={12},
  number={3},
  year={2011}
}


@article{balle_privacy_2018,
  title={Privacy amplification by subsampling: Tight analyses via couplings and divergences},
  author={Balle, Borja and Barthe, Gilles and Gaboardi, Marco},
  journal={arXiv preprint arXiv:1807.01647},
  year={2018}
}


@inproceedings{bassily_private_2014,
  title={Private empirical risk minimization: Efficient algorithms and tight error bounds},
  author={Bassily, Raef and Smith, Adam and Thakurta, Abhradeep},
  booktitle={2014 IEEE 55th Annual Symposium on Foundations of Computer Science},
  pages={464--473},
  year={2014},
  organization={IEEE}
}


@article{wang_differentially_2018,
  title={Differentially private empirical risk minimization revisited: Faster and more general},
  author={Wang, Di and Ye, Minwei and Xu, Jinhui},
  journal={arXiv preprint arXiv:1802.05251},
  year={2018}
}


@inproceedings{talwar_nearly_2015,
  title={Nearly-optimal private LASSO},
  author={Talwar, Kunal and Thakurta, Abhradeep and Zhang, Li},
  booktitle={Proceedings of the 28th International Conference on Neural Information Processing Systems-Volume 2},
  pages={3025--3033},
  year={2015}
}


@article{nesterov_efficiency_2012,
  title={Efficiency of coordinate descent methods on huge-scale optimization problems},
  author={Nesterov, Yu},
  journal={SIAM Journal on Optimization},
  volume={22},
  number={2},
  pages={341--362},
  year={2012},
  publisher={SIAM}
}


@inproceedings{nutini_coordinate_2015,
  title={Coordinate descent converges faster with the gauss-southwell rule than random selection},
  author={Nutini, Julie and Schmidt, Mark and Laradji, Issam and Friedlander, Michael and Koepke, Hoyt},
  booktitle={International Conference on Machine Learning},
  pages={1632--1641},
  year={2015},
  organization={PMLR}
}

@inproceedings{abadi_deep_2016,
  title={Deep learning with differential privacy},
  author={Abadi, Martin and Chu, Andy and Goodfellow, Ian and McMahan, H Brendan and Mironov, Ilya and Talwar, Kunal and Zhang, Li},
  booktitle={Proceedings of the 2016 ACM SIGSAC conference on computer and communications security},
  pages={308--318},
  year={2016}
}

@article{beimel_bounds_2014,
  title={Bounds on the sample complexity for private learning and private data release},
  author={Beimel, Amos and Brenner, Hai and Kasiviswanathan, Shiva Prasad and Nissim, Kobbi},
  journal={Machine learning},
  volume={94},
  number={3},
  pages={401--437},
  year={2014},
  publisher={Springer}
}

@inproceedings{shamir_stochastic_2013,
  title={Stochastic gradient descent for non-smooth optimization: Convergence results and optimal averaging schemes},
  author={Shamir, Ohad and Zhang, Tong},
  booktitle={International conference on machine learning},
  pages={71--79},
  year={2013},
  organization={PMLR}
}

@article{zhang_gradient_2019,
  title={Why gradient clipping accelerates training: A theoretical justification for adaptivity},
  author={Zhang, Jingzhao and He, Tianxing and Sra, Suvrit and Jadbabaie, Ali},
  journal={arXiv preprint arXiv:1905.11881},
  year={2019}
}

@article{chen_understanding_2020,
  title={Understanding gradient clipping in private SGD: A geometric perspective},
  author={Chen, Xiangyi and Wu, Zhiwei Steven and Hong, Mingyi},
  journal={arXiv preprint arXiv:2006.15429},
  year={2020}
}

@inproceedings{nutini_coordinate_2015,
  title={Coordinate descent converges faster with the gauss-southwell rule than random selection},
  author={Nutini, Julie and Schmidt, Mark and Laradji, Issam and Friedlander, Michael and Koepke, Hoyt},
  booktitle={International Conference on Machine Learning},
  pages={1632--1641},
  year={2015},
  organization={PMLR}
}


@inproceedings{bellet_personalized_2018,
  title={Personalized and private peer-to-peer machine learning},
  author={Bellet, Aur{\'e}lien and Guerraoui, Rachid and Taziki, Mahsa and Tommasi, Marc},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={473--481},
  year={2018},
  organization={PMLR}
}

@article{damaskinosdifferentially_2020,
  title={Differentially Private Stochastic Coordinate Descent},
  author={Damaskinos, Georgios and Mendler-D{\"u}nner, Celestine and Guerraoui, Rachid and Papandreou, Nikolaos and Parnell, Thomas},
  journal={arXiv preprint arXiv:2006.07272},
  year={2020}
}

