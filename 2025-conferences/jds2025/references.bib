@inproceedings{mcmahan2017communication,
  title={Communication-efficient learning of deep networks from decentralized data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  booktitle={Artificial intelligence and statistics},
  pages={1273--1282},
  year={2017},
  organization={PMLR}
}

@inproceedings{mcmahan2017communicationoral,
  title={Communication-efficient learning of deep networks from decentralized data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  booktitle={AISTATS},
  year={2017}
}


@article{konevcny2016federated,
  title={Federated Learning: Strategies for Improving Communication Efficiency},
  author={Kone{\v{c}}n{\`y}, Jakub},
  journal={arXiv preprint arXiv:1610.05492},
  year={2016}
}

@inproceedings{karimireddy2020scaffold,
  title={Scaffold: Stochastic controlled averaging for federated learning},
  author={Karimireddy, Sai Praneeth and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank and Stich, Sebastian and Suresh, Ananda Theertha},
  booktitle={International conference on machine learning},
  pages={5132--5143},
  year={2020},
  organization={PMLR}
}

@inproceedings{karimireddy2020scaffoldshort,
  title={Scaffold: Stochastic controlled averaging for federated learning},
  author={Karimireddy, Sai Praneeth and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank and Stich, Sebastian and Suresh, Ananda Theertha},
  booktitle={ICML},
  year={2020}
}


@inproceedings{mishchenko2022proxskip,
  title={Proxskip: Yes! local gradient steps provably lead to communication acceleration! finally!},
  author={Mishchenko, Konstantin and Malinovsky, Grigory and Stich, Sebastian and Richt{\'a}rik, Peter},
  booktitle={International Conference on Machine Learning},
  pages={15750--15769},
  year={2022},
  organization={PMLR}
}



@inproceedings{mishchenko2022proxskipshort,
  title={Proxskip: Yes! local gradient steps provably lead to communication acceleration! finally!},
  author={Mishchenko, Konstantin and Malinovsky, Grigory and Stich, Sebastian and Richt{\'a}rik, Peter},
  booktitle={ICML},
  year={2022}
}


@article{condat2022randprox,
  title={RandProx: Primal-dual optimization algorithms with randomized proximal updates},
  author={Condat, Laurent and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:2207.12891},
  year={2022}
}

@article{malinovsky2022variance,
  title={Variance reduced proxskip: Algorithm, theory and application to federated learning},
  author={Malinovsky, Grigory and Yi, Kai and Richt{\'a}rik, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={15176--15189},
  year={2022}
}


@article{condat2022provably,
  title={Provably doubly accelerated federated learning: The first theoretically successful combination of local training and communication compression},
  author={Condat, Laurent and Agarsk{\`y}, Ivan and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:2210.13277},
  year={2022}
}


@inproceedings{stich2019local,
  title={Local SGD Converges Fast and Communicates Little},
  author={Stich, Sebastian U},
year=2019,
  booktitle={International Conference on Learning Representations}
}



@article{haddadpour2019convergence,
  title={On the convergence of local descent methods in federated learning},
  author={Haddadpour, Farzin and Mahdavi, Mehrdad},
  journal={arXiv preprint arXiv:1910.14425},
  year={2019}
}


@inproceedings{yu2019parallel,
  title={Parallel restarted SGD with faster convergence and less communication: Demystifying why model averaging works for deep learning},
  author={Yu, Hao and Yang, Sen and Zhu, Shenghuo},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={33},
  pages={5693--5700},
  year={2019}
}


@article{li2019communication,
  title={Communication-efficient local decentralized SGD methods},
  author={Li, Xiang and Yang, Wenhao and Wang, Shusen and Zhang, Zhihua},
  journal={arXiv preprint arXiv:1910.09126},
  year={2019}
}




@article{kairouz2021advances,
  title={Advances and open problems in federated learning},
  author={Kairouz, Peter and McMahan, H Brendan and Avent, Brendan and Bellet, Aur{\'e}lien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Kallista and Charles, Zachary and Cormode, Graham and Cummings, Rachel and others},
  journal={Foundations and trends{\textregistered} in machine learning},
  volume={14},
  number={1--2},
  pages={1--210},
  year={2021},
  publisher={Now Publishers, Inc.}
}

@article{yang2019federated,
  title={Federated machine learning: Concept and applications},
  author={Yang, Qiang and Liu, Yang and Chen, Tianjian and Tong, Yongxin},
  journal={ACM Transactions on Intelligent Systems and Technology (TIST)},
  volume={10},
  number={2},
  pages={1--19},
  year={2019},
  publisher={ACM New York, NY, USA}
}


@article{li2020federated,
  title={Federated learniempiricalng: Challenges, methods, and future directions},
  author={Li, Tian and Sahu, Anit Kumar and Talwalkar, Ameet and Smith, Virginia},
  journal={IEEE signal processing magazine},
  volume={37},
  number={3},
  pages={50--60},
  year={2020},
  publisher={IEEE}
}

@article{li2020federatedOptimization,
  title={Federated optimization in heterogeneous networks},
  author={Li, Tian and Sahu, Anit Kumar and Zaheer, Manzil and Sanjabi, Maziar and Talwalkar, Ameet and Smith, Virginia},
  journal={Proceedings of Machine learning and systems},
  volume={2},
  pages={429--450},
  year={2020}
}

@article{pathak2020fedsplit,
  title={FedSplit: An algorithmic framework for fast federated optimization},
  author={Pathak, Reese and Wainwright, Martin J},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={7057--7066},
  year={2020}
}
@inproceedings{malinovskiy2020local,
  title={From local SGD to local fixed-point methods for federated learning},
  author={Malinovskiy, Grigory and Kovalev, Dmitry and Gasanov, Elnur and Condat, Laurent and Richtarik, Peter},
  booktitle={ICML},
  year={2020}
}

@inproceedings{charles2021convergence,
  title={Convergence and accuracy trade-offs in federated learning and meta-learning},
  author={Charles, Zachary and Kone{\v{c}}n{\`y}, Jakub},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2575--2583},
  year={2021},
  organization={PMLR}
}


@article{li2019convergence,
  title={On the convergence of fedavg on non-iid data},
  author={Li, Xiang and Huang, Kaixuan and Yang, Wenhao and Wang, Shusen and Zhang, Zhihua},
  journal={arXiv preprint arXiv:1907.02189},
  year={2019}
}

@article{zhao2018federated,
  title={Federated learning with non-iid data},
  author={Zhao, Yue and Li, Meng and Lai, Liangzhen and Suda, Naveen and Civin, Damon and Chandra, Vikas},
  journal={arXiv preprint arXiv:1806.00582},
  year={2018}
}

@inproceedings{li2022federated,
  title={Federated learning on non-iid data silos: An experimental study},
  author={Li, Qinbin and Diao, Yiqun and Chen, Quan and He, Bingsheng},
  booktitle={2022 IEEE 38th international conference on data engineering (ICDE)},
  pages={965--978},
  year={2022},
  organization={IEEE}
}


@inproceedings{glasgow2022sharp,
  title={Sharp bounds for federated averaging (local sgd) and continuous perspective},
  author={Glasgow, Margalit R and Yuan, Honglin and Ma, Tengyu},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={9050--9090},
  year={2022},
  organization={PMLR}
}

@inproceedings{patel2023still,
  title={On the still unreasonable effectiveness of federated averaging for heterogeneous distributed learning},
  author={Patel, Kumar Kshitij and Glasgow, Margalit and Wang, Lingxiao and Joshi, Nirmit and Srebro, Nathan},
  booktitle={Federated Learning and Analytics in Practice: Algorithms, Systems, Applications, and Opportunities},
  year={2023}
}



@article{wang2024Unreasonable,
  author       = {Jianyu Wang and
                  Rudrajit Das and
                  Gauri Joshi and
                  Satyen Kale and
                  Zheng Xu and
                  Tong Zhang},
  title        = {On the Unreasonable Effectiveness of Federated Averaging with Heterogeneous
                  Data},
  journal      = {TMLR},
  volume       = {2024},
  year         = {2024},
  timestamp    = {Thu, 08 Aug 2024 15:22:39 +0200}
}

@inproceedings{reddi2021adaptive,
  title={Adaptive Federated Optimization},
  author={Reddi, Sashank J and Charles, Zachary and Zaheer, Manzil and Garrett, Zachary and Rush, Keith and Kone{\v{c}}n{\`y}, Jakub and Kumar, Sanjiv and McMahan, Hugh Brendan},
  booktitle={International Conference on Learning Representations},
year=2021
}

@inproceedings{wu2023anchor,
  title={Anchor sampling for federated learning with partial client participation},
  author={Wu, Feijie and Guo, Song and Qu, Zhihao and He, Shiqi and Liu, Ziming and Gao, Jing},
  booktitle={International Conference on Machine Learning},
  pages={37379--37416},
  year={2023},
  organization={PMLR}
}

@inproceedings{li2021model,
  title={Model-contrastive federated learning},
  author={Li, Qinbin and He, Bingsheng and Song, Dawn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10713--10722},
  year={2021}
}



@article{johnson2013accelerating,
  title={Accelerating stochastic gradient descent using predictive variance reduction},
  author={Johnson, Rie and Zhang, Tong},
  journal={Advances in neural information processing systems},
  volume={26},
  year={2013}
}


@inproceedings{yu2019linear,
  title={On the linear speedup analysis of communication efficient momentum SGD for distributed non-convex optimization},
  author={Yu, Hao and Jin, Rong and Yang, Sen},
  booktitle={International Conference on Machine Learning},
  pages={7184--7193},
  year={2019},
  organization={PMLR}
}

@inproceedings{khaled2020tighter,
  title={Tighter theory for local SGD on identical and heterogeneous data},
  author={Khaled, Ahmed and Mishchenko, Konstantin and Richt{\'a}rik, Peter},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4519--4529},
  year={2020},
  organization={PMLR}
}


@inproceedings{zindari2023convergence,
  title={On the convergence of local SGD under third-order smoothness and hessian similarity},
  author={Zindari, Ali and Luo, Ruichen and Stich, Sebastian U},
  booktitle={OPT 2023: Optimization for Machine Learning},
  year={2023}
}


@article{crawshaw2024federated,
  title={Federated learning with client subsampling, data heterogeneity, and unbounded smoothness: A new algorithm and lower bounds},
  author={Crawshaw, Michael and Bao, Yajie and Liu, Mingrui},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{arjevani2015communication,
  title={Communication complexity of distributed convex learning and optimization},
  author={Arjevani, Yossi and Shamir, Ohad},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}


@article{sadiev2022communication,
  title={Communication acceleration of local gradient methods via an accelerated primal-dual algorithm with an inexact prox},
  author={Sadiev, Abdurakhmon and Kovalev, Dmitry and Richt{\'a}rik, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={21777--21791},
  year={2022}
}
@inproceedings{grudzien2023can,
  title={Can 5th generation local training methods support client sampling? yes!},
  author={Grudzie{\'n}, Micha{\l} and Malinovsky, Grigory and Richt{\'a}rik, Peter},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1055--1092},
  year={2023},
  organization={PMLR}
}
@article{yang2021achieving,
  title={Achieving linear speedup with partial worker participation in non-iid federated learning},
  author={Yang, Haibo and Fang, Minghong and Liu, Jia},
  journal={arXiv preprint arXiv:2101.11203},
  year={2021}
}

@inproceedings{qu2021federated,
  title={Federated learning’s blessing: Fedavg has linear speedup},
  author={Qu, Zhaonan and Lin, Kaixiang and Li, Zhaojian and Zhou, Jiayu},
  booktitle={ICLR 2021-Workshop on Distributed and Private Machine Learning (DPML)},
  year={2021}
}

@article{qu2023unified,
  title={A Unified Linear Speedup Analysis of Federated Averaging and Nesterov FedAvg},
  author={Qu, Zhaonan and Lin, Kaixiang and Li, Zhaojian and Zhou, Jiayu and Zhou, Zhengyuan},
  journal={Journal of Artificial Intelligence Research},
  volume={78},
  pages={1143--1200},
  year={2023}
}
@article{polyak1990new,
  title={New stochastic approximation type procedures},
  author={Polyak, Boris T},
  journal={Automat. i Telemekh},
  volume={7},
  number={98-107},
  pages={2},
  year={1990}
}


@article{ruppert1988efficient,
  title={Efficient estimations from a slowly convergent Robbins-Monro process},
  author={Ruppert, David},
  year={1988},
  institution={Cornell University Operations Research and Industrial Engineering}
}

@article{polyak1992acceleration,
  title={Acceleration of stochastic approximation by averaging},
  author={Polyak, Boris T and Juditsky, Anatoli B},
  journal={SIAM journal on control and optimization},
  volume={30},
  number={4},
  pages={838--855},
  year={1992},
  publisher={SIAM}
}




@InProceedings{woodworth2020local,
  title = 	 {Is Local {SGD} Better than Minibatch {SGD}?},
  author =       {Woodworth, Blake and Patel, Kumar Kshitij and Stich, Sebastian and Dai, Zhen and Bullins, Brian and Mcmahan, Brendan and Shamir, Ohad and Srebro, Nathan},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {10334--10343},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/woodworth20a/woodworth20a.pdf},
  abstract = 	 {We study local SGD (also known as parallel SGD and federated SGD), a natural and frequently used distributed optimization method. Its theoretical foundations are currently lacking and we highlight how all existing error guarantees in the convex setting are dominated by a simple baseline, minibatch SGD. (1) For quadratic objectives we prove that local SGD strictly dominates minibatch SGD and that accelerated local SGD is minmax optimal for quadratics; (2) For general convex objectives we provide the first guarantee that at least \emph{sometimes} improves over minibatch SGD, but our guarantee does not always improve over, nor even match, minibatch SGD; (3) We show that indeed local SGD does \emph{not} dominate minibatch SGD by presenting a lower bound on the performance of local SGD that is worse than the minibatch SGD guarantee.}
}


@inproceedings{mishchenko2022asynchronous,
 author = {Mishchenko, Konstantin and Bach, Francis and Even, Mathieu and Woodworth, Blake E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {420--433},
 publisher = {Curran Associates, Inc.},
 title = {Asynchronous SGD Beats Minibatch SGD Under Arbitrary Delays},
 volume = {35},
 year = {2022}
}
@article{gadat2023optimal,
  title={Optimal non-asymptotic analysis of the Ruppert--Polyak averaging stochastic algorithm},
  author={Gadat, S{\'e}bastien and Panloup, Fabien},
  journal={Stochastic Processes and their Applications},
  volume={156},
  pages={312--348},
  year={2023},
  publisher={Elsevier}
}
@article{dieuleveut2020bridging,
  title={Bridging the gap between constant step size stochastic gradient descent and markov chains},
  author={Dieuleveut, Aymeric and Durmus, Alain and Bach, Francis},
  year={2020}
}


@article{moulines2011non,
  title={Non-asymptotic analysis of stochastic approximation algorithms for machine learning},
  author={Moulines, Eric and Bach, Francis},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}
@article{bach2013non,
  title={Non-strongly-convex smooth stochastic approximation with convergence rate O (1/n)},
  author={Bach, Francis and Moulines, Eric},
  journal={Advances in neural information processing systems},
  volume={26},
  year={2013}
}
@article{nemirovski2009robust,
  title={Robust stochastic approximation approach to stochastic programming},
  author={Nemirovski, Arkadi and Juditsky, Anatoli and Lan, Guanghui and Shapiro, Alexander},
  journal={SIAM Journal on optimization},
  volume={19},
  number={4},
  pages={1574--1609},
  year={2009},
  publisher={SIAM}
}

@article{hunter1986exponentially,
  title={The exponentially weighted moving average},
  author={Hunter, J Stuart},
  journal={Journal of quality technology},
  volume={18},
  number={4},
  pages={203--210},
  year={1986},
  publisher={Taylor \& Francis}
}


@inproceedings{defazio2024road,
  title={The road less scheduled},
  author={Defazio, Aaron and Yang, Xingyu Alice and Mehta, Harsh and Mishchenko, Konstantin and Khaled, Ahmed and Cutkosky, Ashok},
 booktitle = {Advances in Neural Information Processing Systems},
  year={2024}
}

@article{morales2024exponential,
  title={Exponential moving average of weights in deep learning: Dynamics and benefits},
  author={Morales-Brotons, Daniel and Vogels, Thijs and Hendrikx, Hadrien},
  journal={Transactions on Machine Learning Research},
  year={2024}
}

@inproceedings{nesterov1983method,
  title={A method for solving the convex programming problem with convergence rate O (1/k2)},
  author={Nesterov, Yurii},
  booktitle={Dokl akad nauk Sssr},
  volume={269},
  pages={543},
  year={1983}
}

@inproceedings{muecke2019beating,
 author = {Muecke, Nicole and Neu, Gergely and Rosasco, Lorenzo},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Beating SGD Saturation with Tail-Averaging  and Minibatching},
 volume = {32},
 year = {2019}
}
@article{jain2018parallelizing,
  author  = {Prateek Jain and Sham M. Kakade and Rahul Kidambi and Praneeth Netrapalli and Aaron Sidford},
  title   = {Parallelizing Stochastic Gradient Descent for Least Squares Regression: Mini-batching, Averaging, and Model Misspecification},
  journal = {Journal of Machine Learning Research},
  year    = {2018},
  volume  = {18},
  number  = {223},
  pages   = {1--42}
}
@article{tao2018primal,
  title={Primal averaging: A new gradient evaluation step to attain the optimal individual convergence},
  author={Tao, Wei and Pan, Zhisong and Wu, Gaowei and Tao, Qing},
  journal={IEEE transactions on cybernetics},
  volume={50},
  number={2},
  pages={835--845},
  year={2018},
  publisher={IEEE}
}

@article{nesterov2015quasi,
  title={Quasi-monotone subgradient methods for nonsmooth convex minimization},
  author={Nesterov, Yu and Shikhman, Vladimir},
  journal={Journal of Optimization Theory and Applications},
  volume={165},
  number={3},
  pages={917--940},
  year={2015},
  publisher={Springer}
}

@article{mishchenko2023prodigy,
  title={Prodigy: An expeditiously adaptive parameter-free learner},
  author={Mishchenko, Konstantin and Defazio, Aaron},
  journal={arXiv preprint arXiv:2306.06101},
  year={2023}
}

@inproceedings{defazio2023learning,
  title={Learning-rate-free learning by d-adaptation},
  author={Defazio, Aaron and Mishchenko, Konstantin},
  booktitle={International Conference on Machine Learning},
  pages={7449--7479},
  year={2023},
  organization={PMLR}
}

@article{orabona2014simultaneous,
  title={Simultaneous model selection and optimization through parameter-free stochastic learning},
  author={Orabona, Francesco},
  journal={Advances in Neural Information Processing Systems},
  volume={27},
  year={2014}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{defossez2020simple,
  title={A simple convergence proof of adam and adagrad},
  author={D{\'e}fossez, Alexandre and Bottou, L{\'e}on and Bach, Francis and Usunier, Nicolas},
  journal={arXiv preprint arXiv:2003.02395},
  year={2020}
}

@article{duchi2011adaptive,
  title={Adaptive subgradient methods for online learning and stochastic optimization.},
  author={Duchi, John and Hazan, Elad and Singer, Yoram},
  journal={Journal of machine learning research},
  volume={12},
  number={7},
  year={2011}
}

@article{sokolov2024marina,
  title={MARINA-P: Superior Performance in Non-smooth Federated Optimization with Adaptive Stepsizes},
  author={Sokolov, Igor and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:2412.17082},
  year={2024}
}


@article{reddi2020adaptive,
  title={Adaptive federated optimization},
  author={Reddi, Sashank and Charles, Zachary and Zaheer, Manzil and Garrett, Zachary and Rush, Keith and Kone{\v{c}}n{\`y}, Jakub and Kumar, Sanjiv and McMahan, H Brendan},
  journal={arXiv preprint arXiv:2003.00295},
  year={2020}
}

@article{tieleman2012lecture,
  title={Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude},
  author={Tieleman, Tijmen},
  journal={COURSERA: Neural networks for machine learning},
  volume={4},
  number={2},
  pages={26},
  year={2012}
}


@inproceedings{loshchilov2016sgdr,
  title={Sgdr: Stochastic gradient descent with warm restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
  booktitle={International Conference on Learning Representations},
  year={2017}
}

@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, I},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{beutel2020flower,
  title={Flower: A friendly federated learning research framework},
  author={Beutel, Daniel J and Topal, Taner and Mathur, Akhil and Qiu, Xinchi and Fernandez-Marques, Javier and Gao, Yan and Sani, Lorenzo and Li, Kwing Hei and Parcollet, Titouan and de Gusm{\~a}o, Pedro Porto Buarque and others},
  journal={arXiv preprint arXiv:2007.14390},
  year={2020}
}




@inproceedings{bellet2018personalized,
  title={Personalized and private peer-to-peer machine learning},
  author={Bellet, Aur{\'e}lien and Guerraoui, Rachid and Taziki, Mahsa and Tommasi, Marc},
  booktitle={International conference on artificial intelligence and statistics},
  pages={473--481},
  year={2018},
  organization={PMLR}
}

@article{lian2017can,
  title={Can decentralized algorithms outperform centralized algorithms? a case study for decentralized parallel SGD},
  author={Lian, Xiangru and Zhang, Ce and Zhang, Huan and Hsieh, Cho-Jui and Zhang, Wei and Liu, Ji},
  journal={NeurIPS},
  year={2017}
}

@article{wang2020tackling,
  title={Tackling the objective inconsistency problem in heterogeneous federated optimization},
  author={Wang, Jianyu and Liu, Qinghua and Liang, Hao and Joshi, Gauri and Poor, H Vincent},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={7611--7623},
  year={2020}
}


@inproceedings{wu2023faster,
  title={Faster adaptive federated learning},
  author={Wu, Xidong and Huang, Feihu and Hu, Zhengmian and Huang, Heng},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={37},
  number={9},
  pages={10379--10387},
  year={2023}
}

@article{khaled2023dowg,
  title={Dowg unleashed: An efficient universal parameter-free gradient descent method},
  author={Khaled, Ahmed and Mishchenko, Konstantin and Jin, Chi},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={6748--6769},
  year={2023}
}

@article{recht2011hogwild,
  title={Hogwild!: A lock-free approach to parallelizing stochastic gradient descent},
  author={Recht, Benjamin and Re, Christopher and Wright, Stephen and Niu, Feng},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}

@book{bertsekas1997parallel,
  title={Parallel and distributed computation: numerical methods},
  author={Bertsekas, Dimitri and Tsitsiklis, John},
  year={1997},
  publisher={Athena Scientific}
}

@article{dekel2012optimal,
  title={Optimal Distributed Online Prediction Using Mini-Batches.},
  author={Dekel, Ofer and Gilad-Bachrach, Ran and Shamir, Ohad and Xiao, Lin},
  journal={Journal of Machine Learning Research},
  volume={13},
  number={1},
  year={2012}
}

@article{agarwal2010distributed,
  title={Distributed dual averaging in networks},
  author={Agarwal, Alekh and Wainwright, Martin J and Duchi, John C},
  journal={Advances in Neural Information Processing Systems},
  volume={23},
  year={2010}
}


@article{feyzmahdavian2016asynchronous,
  title={An asynchronous mini-batch algorithm for regularized stochastic optimization},
  author={Feyzmahdavian, Hamid Reza and Aytekin, Arda and Johansson, Mikael},
  journal={IEEE Transactions on Automatic Control},
  volume={61},
  number={12},
  pages={3740--3754},
  year={2016},
  publisher={IEEE}
}

@inproceedings{nguyen2018sgd,
  title={SGD and Hogwild! convergence without the bounded gradients assumption},
  author={Nguyen, Lam and Nguyen, Phuong Ha and Dijk, Marten and Richt{\'a}rik, Peter and Scheinberg, Katya and Tak{\'a}c, Martin},
  booktitle={International Conference on Machine Learning},
  pages={3750--3758},
  year={2018},
  organization={PMLR}
}

@inproceedings{arjevani2020tight,
  title={A tight convergence analysis for stochastic gradient descent with delayed updates},
  author={Arjevani, Yossi and Shamir, Ohad and Srebro, Nathan},
  booktitle={Algorithmic Learning Theory},
  pages={111--132},
  year={2020},
  organization={PMLR}
}

@article{cohen2021asynchronous,
  title={Asynchronous stochastic optimization robust to arbitrary delays},
  author={Cohen, Alon and Daniely, Amit and Drori, Yoel and Koren, Tomer and Schain, Mariano},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={9024--9035},
  year={2021}
}

@article{koloskova2022sharper,
  title={Sharper convergence guarantees for asynchronous SGD for distributed and federated learning},
  author={Koloskova, Anastasiia and Stich, Sebastian U and Jaggi, Martin},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={17202--17215},
  year={2022}
}


@inproceedings{islamov2024asgrad,
  title={AsGrad: A sharp unified analysis of asynchronous-SGD algorithms},
  author={Islamov, Rustem and Safaryan, Mher and Alistarh, Dan},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={649--657},
  year={2024},
  organization={PMLR}
}



@inproceedings{yang2022anarchic,
  title={Anarchic federated learning},
  author={Yang, Haibo and Zhang, Xin and Khanduri, Prashant and Liu, Jia},
  booktitle={International Conference on Machine Learning},
  pages={25331--25363},
  year={2022},
  organization={PMLR}
}

@inproceedings{hendrikx2019accelerated,
  title={Accelerated decentralized optimization with local updates for smooth and strongly convex objectives},
  author={Hendrikx, Hadrien and Bach, Francis and Massouli{\'e}, Laurent},
  booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
  pages={897--906},
  year={2019},
  organization={PMLR}
}

@article{even2024asynchronous,
  title={Asynchronous speedup in decentralized optimization},
  author={Even, Mathieu and Hendrikx, Hadrien and Massouli{\'e}, Laurent},
  journal={IEEE Transactions on Automatic Control},
  year={2024},
  publisher={IEEE}
}


@inproceedings{lian2018asynchronous,
  title={Asynchronous decentralized parallel stochastic gradient descent},
  author={Lian, Xiangru and Zhang, Wei and Zhang, Ce and Liu, Ji},
  booktitle={International Conference on Machine Learning},
  pages={3043--3052},
  year={2018},
  organization={PMLR}
}

@article{scaman2019optimal,
  title={Optimal convergence rates for convex distributed optimization in networks},
  author={Scaman, Kevin and Bach, Francis and Bubeck, S{\'e}bastien and Lee, Yin Tat and Massouli{\'e}, Laurent},
  journal={Journal of Machine Learning Research},
  volume={20},
  number={159},
  pages={1--31},
  year={2019}
}
@article{gorbunov2019optimal,
  title={Optimal decentralized distributed algorithms for stochastic convex optimization},
  author={Gorbunov, Eduard and Dvinskikh, Darina and Gasnikov, Alexander},
  journal={arXiv preprint arXiv:1911.07363},
  year={2019}
}

@inproceedings{leconte2024queuing,
  title={Queuing dynamics of asynchronous Federated Learning},
  author={Leconte, Louis and Jonckheere, Matthieu and Samsonov, Sergey and Moulines, Eric},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1711--1719},
  year={2024},
  organization={PMLR}
}


@article{maranjyan2024mindflayer,
  title={MindFlayer: Efficient Asynchronous Parallel SGD in the Presence of Heterogeneous and Random Worker Compute Times},
  author={Maranjyan, Artavazd and Omar, Omar Shaikh and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:2410.04285},
  year={2024}
}


@article{agarwal2011distributed,
  title={Distributed delayed stochastic optimization},
  author={Agarwal, Alekh and Duchi, John C},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}
@article{leblond2018improved,
  title={Improved asynchronous parallel optimization analysis for stochastic incremental methods},
  author={Leblond, R{\'e}mi and Pedregosa, Fabian and Lacoste-Julien, Simon},
  journal={Journal of Machine Learning Research},
  volume={19},
  number={81},
  pages={1--68},
  year={2018}
}
@article{mania2017perturbed,
  title={Perturbed iterate analysis for asynchronous stochastic optimization},
  author={Mania, Horia and Pan, Xinghao and Papailiopoulos, Dimitris and Recht, Benjamin and Ramchandran, Kannan and Jordan, Michael I},
  journal={SIAM Journal on Optimization},
  volume={27},
  number={4},
  pages={2202--2229},
  year={2017},
  publisher={SIAM}
}
@article{stich2020error,
  title={The error-feedback framework: SGD with delayed gradients},
  author={Stich, Sebastian U and Karimireddy, Sai Praneeth},
  journal={Journal of Machine Learning Research},
  volume={21},
  number={237},
  pages={1--36},
  year={2020}
}


@article{tyurin2024optimal,
  title={Optimal time complexities of parallel stochastic optimization methods under a fixed computation model},
  author={Tyurin, Alexander and Richt{\'a}rik, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}


@inproceedings{avdiukhin2021federated,
  title={Federated learning under arbitrary communication patterns},
  author={Avdiukhin, Dmitrii and Kasiviswanathan, Shiva},
  booktitle={International Conference on Machine Learning},
  pages={425--435},
  year={2021},
  organization={PMLR}
}

@article{hanzely2020lower,
  title={Lower bounds and optimal algorithms for personalized federated learning},
  author={Hanzely, Filip and Hanzely, Slavom{\'\i}r and Horv{\'a}th, Samuel and Richt{\'a}rik, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={2304--2315},
  year={2020}
}


@article{wright2015coordinate,
  title={Coordinate descent algorithms},
  author={Wright, Stephen J},
  journal={Mathematical programming},
  volume={151},
  number={1},
  pages={3--34},
  year={2015},
  publisher={Springer}
}


@article{nesterov2012efficiency,
  title={Efficiency of coordinate descent methods on huge-scale optimization problems},
  author={Nesterov, Yu},
  journal={SIAM Journal on Optimization},
  volume={22},
  number={2},
  pages={341--362},
  year={2012},
  publisher={SIAM}
}

@article{richtarik2014iteration,
  title={Iteration complexity of randomized block-coordinate descent methods for minimizing a composite function},
  author={Richt{\'a}rik, Peter and Tak{\'a}{\v{c}}, Martin},
  journal={Mathematical Programming},
  volume={144},
  number={1},
  pages={1--38},
  year={2014},
  publisher={Springer}
}

@inproceedings{fang2020greed,
  title={Greed meets sparsity: Understanding and improving greedy coordinate descent for sparse optimization},
  author={Fang, Huang and Fan, Zhenan and Sun, Yifan and Friedlander, Michael},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={434--444},
  year={2020},
  organization={PMLR}
}

@inproceedings{karimireddy2019efficient,
  title={Efficient greedy coordinate descent for composite problems},
  author={Karimireddy, Sai Praneeth and Koloskova, Anastasia and Stich, Sebastian U and Jaggi, Martin},
  booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
  pages={2887--2896},
  year={2019},
  organization={PMLR}
}

@article{clarkson2010coresets,
  title={Coresets, sparse greedy approximation, and the Frank-Wolfe algorithm},
  author={Clarkson, Kenneth L},
  journal={ACM Transactions on Algorithms (TALG)},
  volume={6},
  number={4},
  pages={1--30},
  year={2010},
  publisher={ACM New York, NY, USA}
}

@article{qi2021federated,
  title={Federated reinforcement learning: Techniques, applications, and open challenges},
  author={Qi, Jiaju and Zhou, Qihao and Lei, Lei and Zheng, Kan},
  journal={arXiv preprint arXiv:2108.11887},
  year={2021}
}

@article{wang2020federated,
  title={Federated deep reinforcement learning for Internet of Things with decentralized cooperative edge caching},
  author={Wang, Xiaofei and Wang, Chenyang and Li, Xiuhua and Leung, Victor CM and Taleb, Tarik},
  journal={IEEE Internet of Things Journal},
  volume={7},
  number={10},
  pages={9441--9455},
  year={2020},
  publisher={IEEE}
}


@article{agarwal2021theory,
  title={On the theory of policy gradient methods: Optimality, approximation, and distribution shift},
  author={Agarwal, Alekh and Kakade, Sham M and Lee, Jason D and Mahajan, Gaurav},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={98},
  pages={1--76},
  year={2021}
}


@article{zou2019finite,
  title={Finite-sample analysis for sarsa with linear function approximation},
  author={Zou, Shaofeng and Xu, Tengyu and Liang, Yingbin},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{bhandari2018finite,
  title={A finite time analysis of temporal difference learning with linear function approximation},
  author={Bhandari, Jalaj and Russo, Daniel and Singal, Raghav},
  booktitle={Conference on learning theory},
  pages={1691--1692},
  year={2018},
  organization={PMLR}
}

@inproceedings{samsonov2024improved,
  title={Improved High-Probability Bounds for the Temporal Difference Learning Algorithm via Exponential Stability},
  author={Samsonov, Sergey and Tiapkin, Daniil and Naumov, Alexey and Moulines, Eric},
  booktitle={The Thirty Seventh Annual Conference on Learning Theory},
  pages={4511--4547},
  year={2024},
  organization={PMLR}
}


@inproceedings{azar2017minimax,
  title={Minimax regret bounds for reinforcement learning},
  author={Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, R{\'e}mi},
  booktitle={International conference on machine learning},
  pages={263--272},
  year={2017},
  organization={PMLR}
}
@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}

@inproceedings{bagnell2001autonomous,
  title={Autonomous helicopter control using reinforcement learning policy search methods},
  author={Bagnell, J Andrew and Schneider, Jeff G},
  booktitle={Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No. 01CH37164)},
  volume={2},
  pages={1615--1620},
  year={2001},
  organization={IEEE}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group UK London}
}


@article{silver2017mastering,
  title={Mastering chess and shogi by self-play with a general reinforcement learning algorithm},
  author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
  journal={arXiv preprint arXiv:1712.01815},
  year={2017}
}


@article{robbins1951stochastic,
  title={A stochastic approximation method},
  author={Robbins, Herbert and Monro, Sutton},
  journal={The annals of mathematical statistics},
  pages={400--407},
  year={1951},
  publisher={JSTOR}
}

@article{lai2003stochastic,
  title={Stochastic approximation},
  author={Lai, Tze Leung},
  journal={The annals of Statistics},
  volume={31},
  number={2},
  pages={391--406},
  year={2003},
  publisher={Institute of Mathematical Statistics}
}

@article{sutton1988learning,
  title={Learning to predict by the methods of temporal differences},
  author={Sutton, Richard S},
  journal={Machine learning},
  volume={3},
  pages={9--44},
  year={1988},
  publisher={Springer}
}

@article{watkins1989learning,
  title={Learning from delayed rewards},
  author={Watkins, Christopher John Cornish Hellaby},
  year={1989},
  publisher={King's College, Cambridge United Kingdom}
}

@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@article{rummery1994line,
  title={On-line Q-learning using connectionist systems},
  author={Rummery, Gavin A and Niranjan, Mahesan},
  volume={37},
  year={1994},
  publisher={University of Cambridge, Department of Engineering Cambridge, UK}
}

@article{dieuleveut2023stochastic,
  title={Stochastic approximation beyond gradient for signal processing and machine learning},
  author={Dieuleveut, Aymeric and Fort, Gersende and Moulines, Eric and Wai, Hoi-To},
  journal={IEEE Transactions on Signal Processing},
  year={2023},
  publisher={IEEE}
}

@article{xiao2022convergence,
  title={On the convergence rates of policy gradient methods},
  author={Xiao, Lin},
  journal={Journal of Machine Learning Research},
  volume={23},
  number={282},
  pages={1--36},
  year={2022}
}


@inproceedings{mei2020global,
  title={On the global convergence rates of softmax policy gradient methods},
  author={Mei, Jincheng and Xiao, Chenjun and Szepesvari, Csaba and Schuurmans, Dale},
  booktitle={International conference on machine learning},
  pages={6820--6829},
  year={2020},
  organization={PMLR}
}

@article{lan2023policy,
  title={Policy mirror descent for reinforcement learning: Linear convergence, new sampling complexity, and generalized problem classes},
  author={Lan, Guanghui},
  journal={Mathematical programming},
  volume={198},
  number={1},
  pages={1059--1106},
  year={2023},
  publisher={Springer}
}

@inproceedings{gupta2018shampoo,
  title={Shampoo: Preconditioned stochastic tensor optimization},
  author={Gupta, Vineet and Koren, Tomer and Singer, Yoram},
  booktitle={International Conference on Machine Learning},
  pages={1842--1850},
  year={2018},
  organization={PMLR}
}


@article{lee2020federated,
  title={Federated reinforcement learning for energy management of multiple smart homes with distributed energy resources},
  author={Lee, Sangyoon and Choi, Dae-Hyun},
  journal={IEEE Transactions on Industrial Informatics},
  volume={18},
  number={1},
  pages={488--497},
  year={2020},
  publisher={IEEE}
}

@incollection{liang2022federated,
  title={Federated transfer reinforcement learning for autonomous driving},
  author={Liang, Xinle and Liu, Yang and Chen, Tianjian and Liu, Ming and Yang, Qiang},
  booktitle={Federated and Transfer Learning},
  pages={357--371},
  year={2022},
  publisher={Springer}
}

@article{li2022federatedb,
  title={Federated multi-agent deep reinforcement learning for resource allocation of vehicle-to-vehicle communications},
  author={Li, Xiang and Lu, Lingyun and Ni, Wei and Jamalipour, Abbas and Zhang, Dalin and Du, Haifeng},
  journal={IEEE Transactions on Vehicular Technology},
  volume={71},
  number={8},
  pages={8810--8824},
  year={2022},
  publisher={IEEE}
}


@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}


@article{bertsekas2011approximate,
  title={Approximate policy iteration: A survey and some new methods},
  author={Bertsekas, Dimitri P},
  journal={Journal of Control Theory and Applications},
  volume={9},
  number={3},
  pages={310--335},
  year={2011},
  publisher={Springer}
}


@inproceedings{khodadadian2022federated,
  title={Federated reinforcement learning: Linear speedup under markovian sampling},
  author={Khodadadian, Sajad and Sharma, Pranay and Joshi, Gauri and Maguluri, Siva Theja},
  booktitle={International Conference on Machine Learning},
  pages={10997--11057},
  year={2022},
  organization={PMLR}
}

@article{dal2023federated,
  title={Federated td learning over finite-rate erasure channels: Linear speedup under markovian sampling},
  author={Dal Fabbro, Nicol{\`o} and Mitra, Aritra and Pappas, George J},
  journal={IEEE Control Systems Letters},
  volume={7},
  pages={2461--2466},
  year={2023},
  publisher={IEEE}
}


@article{liu2023distributed,
  title={Distributed TD (0) with almost no communication},
  author={Liu, Rui and Olshevsky, Alex},
  journal={IEEE Control Systems Letters},
  volume={7},
  pages={2892--2897},
  year={2023},
  publisher={IEEE}
}

@inproceedings{chen2023byzantine,
  title={Byzantine-robust online and offline distributed reinforcement learning},
  author={Chen, Yiding and Zhang, Xuezhou and Zhang, Kaiqing and Wang, Mengdi and Zhu, Xiaojin},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3230--3269},
  year={2023},
  organization={PMLR}
}

@article{zhang2020almost,
  title={Almost optimal model-free reinforcement learningvia reference-advantage decomposition},
  author={Zhang, Zihan and Zhou, Yuan and Ji, Xiangyang},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={15198--15207},
  year={2020}
}
@inproceedings{zheng2024federated,
  title={Federated Q-Learning: Linear Regret Speedup with Low Communication Cost},
  author={Zheng, Zhong and Gao, Fengyu and Xue, Lingzhou and Yang, Jing},
  booktitle={The Twelfth International Conference on Learning Representations},
year=2024
}


@article{zheng2024federatedb,
  title={Federated Q-Learning with Reference-Advantage Decomposition: Almost Optimal Regret and Logarithmic Communication Cost},
  author={Zheng, Zhong and Zhang, Haochen and Xue, Lingzhou},
  journal={arXiv preprint arXiv:2405.18795},
  year={2024}
}





@article{doan2020local,
  title={Local stochastic approximation: A unified view of federated learning and distributed multi-task reinforcement learning algorithms},
  author={Doan, Thinh T},
  journal={arXiv preprint arXiv:2006.13460},
  year={2020}
}

@inproceedings{doan2019finite,
  title={Finite-time analysis of distributed TD (0) with linear function approximation on multi-agent reinforcement learning},
  author={Doan, Thinh and Maguluri, Siva and Romberg, Justin},
  booktitle={International Conference on Machine Learning},
  pages={1626--1635},
  year={2019},
  organization={PMLR}
}

@inproceedings{jin2022federated,
  title={Federated reinforcement learning with environment heterogeneity},
  author={Jin, Hao and Peng, Yang and Yang, Wenhao and Wang, Shusen and Zhang, Zhihua},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={18--37},
  year={2022},
  organization={PMLR}
}


@article{wang2023federated,
  title={Federated temporal difference learning with linear function approximation under environmental heterogeneity},
  author={Wang, Han and Mitra, Aritra and Hassani, Hamed and Pappas, George J and Anderson, James},
  journal={arXiv preprint arXiv:2302.02212},
  year={2023}
}
@inproceedings{zhang2024finite,
  title={Finite-Time Analysis of On-Policy Heterogeneous Federated Reinforcement Learning},
  author={Zhang, Chenyu and Wang, Han and Mitra, Aritra and Anderson, James},
  booktitle={The Twelfth International Conference on Learning Representations},
year=2024
}

@book{daniels1952average,
  title={The average man?},
  author={Daniels, Gilbert S and Churchill, Edmund},
  year={1952},
  publisher={Wright Air Development Center, Air Research and Development Command, United~…}
}

@article{wang2024convergence,
  title={On the convergence rates of federated q-learning across heterogeneous environments},
  author={Wang, Muxing and Yang, Pengkun and Su, Lili},
  journal={arXiv preprint arXiv:2409.03897},
  year={2024}
}

@inproceedings{vanhaesebrouck2017decentralized,
  title={Decentralized collaborative learning of personalized models over networks},
  author={Vanhaesebrouck, Paul and Bellet, Aur{\'e}lien and Tommasi, Marc},
  booktitle={Artificial Intelligence and Statistics},
  pages={509--517},
  year={2017},
  organization={PMLR}
}


@article{tsitsiklis1994asynchronous,
  title={Asynchronous stochastic approximation and Q-learning},
  author={Tsitsiklis, John N},
  journal={Machine learning},
  volume={16},
  pages={185--202},
  year={1994},
  publisher={Springer}
}


@inproceedings{zhang2023convergence,
  title={On the convergence of SARSA with linear function approximation},
  author={Zhang, Shangtong and Des Combes, Remi Tachet and Laroche, Romain},
  booktitle={International Conference on Machine Learning},
  pages={41613--41646},
  year={2023},
  organization={PMLR}
}

@inproceedings{salgia2024the,
title={The Sample-Communication Complexity Trade-off in Federated Q-Learning},
author={Sudeep Salgia and Yuejie Chi},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024}
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@article{schulman2015trust,
  title={Trust Region Policy Optimization},
  author={Schulman, John},
  journal={arXiv preprint arXiv:1502.05477},
  year={2015}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{zhang2021sample,
  title={Sample efficient reinforcement learning with REINFORCE},
  author={Zhang, Junzi and Kim, Jongho and O'Donoghue, Brendan and Boyd, Stephen},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={35},
  number={12},
  pages={10887--10895},
  year={2021}
}


@article{polyak1963gradient,
  title={Gradient methods for minimizing functionals},
  author={Polyak, Boris Teodorovich},
  journal={Zhurnal vychislitel'noi matematiki i matematicheskoi fiziki},
  volume={3},
  number={4},
  pages={643--653},
  year={1963},
  publisher={Russian Academy of Sciences, Branch of Mathematical Sciences}
}

@inproceedings{wang2024momentum,
  title={Momentum for the Win: Collaborative Federated Reinforcement Learning across Heterogeneous Environments},
  author={Wang, Han and He, Sihong and Zhang, Zhili and Miao, Fei and Anderson, James},
  booktitle={Forty-first International Conference on Machine Learning},
year=2024
}

@article{chen2021communication,
  title={Communication-efficient policy gradient methods for distributed reinforcement learning},
  author={Chen, Tianyi and Zhang, Kaiqing and Giannakis, Georgios B and Ba{\c{s}}ar, Tamer},
  journal={IEEE Transactions on Control of Network Systems},
  volume={9},
  number={2},
  pages={917--929},
  year={2021},
  publisher={IEEE}
}

@article{ganesh2024global,
  title={Global Convergence Guarantees for Federated Policy Gradient Methods with Adversaries},
  author={Ganesh, Swetha and Chen, Jiayu and Thoppe, Gugan and Aggarwal, Vaneet},
  journal={arXiv preprint arXiv:2403.09940},
  year={2024}
}

@article{lan2023improved,
  title={Improved communication efficiency in federated natural policy gradient via admm-based gradient updates},
  author={Lan, Guangchen and Wang, Han and Anderson, James and Brinton, Christopher and Aggarwal, Vaneet},
  journal={arXiv preprint arXiv:2310.19807},
  year={2023}
}

@article{lan2024asynchronous,
  title={Asynchronous federated reinforcement learning with policy gradient updates: Algorithm design and convergence analysis},
  author={Lan, Guangchen and Han, Dong-Jun and Hashemi, Abolfazl and Aggarwal, Vaneet and Brinton, Christopher G},
  journal={arXiv preprint arXiv:2404.08003},
  year={2024}
}
@article{lojasiewicz1963topological,
  title={A topological property of real analytic subsets},
  author={Lojasiewicz, Stanislaw},
  journal={Coll. du CNRS, Les {\'e}quations aux d{\'e}riv{\'e}es partielles},
  volume={117},
  number={87-89},
  pages={2},
  year={1963}
}

@article{lojasiewicz1982trajectoires,
  title={Sur les trajectoires du gradient d’une fonction analytique},
  author={Lojasiewicz, Stanislaw},
  journal={Seminari di geometria},
  volume={1983},
  pages={115--117},
  year={1982}
}


@article{zhu2019deep,
  title={Deep leakage from gradients},
  author={Zhu, Ligeng and Liu, Zhijian and Han, Song},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}


@article{geiping2020inverting,
  title={Inverting gradients-how easy is it to break privacy in federated learning?},
  author={Geiping, Jonas and Bauermeister, Hartmut and Dr{\"o}ge, Hannah and Moeller, Michael},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={16937--16947},
  year={2020}
}
@article{zhao2020idlg,
  title={idlg: Improved deep leakage from gradients},
  author={Zhao, Bo and Mopuri, Konda Reddy and Bilen, Hakan},
  journal={arXiv preprint arXiv:2001.02610},
  year={2020}
}
@inproceedings{wang2019beyond,
  title={Beyond inferring class representatives: User-level privacy leakage from federated learning},
  author={Wang, Zhibo and Song, Mengkai and Zhang, Zhifei and Song, Yang and Wang, Qian and Qi, Hairong},
  booktitle={IEEE INFOCOM 2019-IEEE conference on computer communications},
  pages={2512--2520},
  year={2019},
  organization={IEEE}
}

@inproceedings{kariyappa2023cocktail,
  title={Cocktail party attack: Breaking aggregation-based privacy in federated learning using independent component analysis},
  author={Kariyappa, Sanjay and Guo, Chuan and Maeng, Kiwan and Xiong, Wenjie and Suh, G Edward and Qureshi, Moinuddin K and Lee, Hsien-Hsin S},
  booktitle={International Conference on Machine Learning},
  pages={15884--15899},
  year={2023},
  organization={PMLR}
}
@inproceedings{el2024privacy,
  title={Privacy Attacks in Decentralized Learning},
  author={El Mrini, Abdellah and Cyffers, Edwige and Bellet, Aur{\'e}lien},
  booktitle={Forty-first International Conference on Machine Learning},
year=2024
}
@inproceedings{bhagoji2019analyzing,
  title={Analyzing federated learning through an adversarial lens},
  author={Bhagoji, Arjun Nitin and Chakraborty, Supriyo and Mittal, Prateek and Calo, Seraphin},
  booktitle={International conference on machine learning},
  pages={634--643},
  year={2019},
  organization={PMLR}
}

@article{cadwalladr2018revealed,
  title={Revealed: 50 million Facebook profiles harvested for Cambridge Analytica in major data breach},
  author={Cadwalladr, Carole and Graham-Harrison, Emma},
  journal={The guardian},
  volume={17},
  number={1},
  pages={22},
  year={2018},
  publisher={London, UK}
}

@inproceedings{buolamwini2018gender,
  title={Gender shades: Intersectional accuracy disparities in commercial gender classification},
  author={Buolamwini, Joy and Gebru, Timnit},
  booktitle={Conference on fairness, accountability and transparency},
  pages={77--91},
  year={2018},
  organization={PMLR}
}

@article{ec2019ethics,
  abstract = {The aim of the Guidelines is to promote Trustworthy AI. Trustworthy AI has three components, which should be met throughout the system's entire life cycle: (1) it should be lawful, complying with all applicable laws and regulations (2) it should be ethical, ensuring adherence to ethical principles and values and (3) it should be robust, both from a technical and social perspective since, even with good intentions, AI systems can cause unintentional harm. Each component in itself is necessary but not sufficient for the achievement of Trustworthy AI. Ideally, all three components work in harmony and overlap in their operation. If, in practice, tensions arise between these components, society should endeavour to align them.},
  added-at = {2019-04-09T00:11:27.000+0200},
  address = {Brussels},
  author = {{High-Level Expert Group on AI (European Commission)}},
  institution = {European Commission},
  interhash = {93470c404e192934581de16f3d35d74c},
  intrahash = {b8324eab4054c40237eba8840fe04345},
  keywords = {European_Commission artificial_intelligence digital_ethics discrimination ethics},
  language = {eng},
  month = apr,
  timestamp = {2019-04-09T00:11:27.000+0200},
  title = {Ethics guidelines for trustworthy AI},
  type = {Report},
  url = {https://ec.europa.eu/digital-single-market/en/news/ethics-guidelines-trustworthy-ai},
  year = 2019
}


@inproceedings{dwork2006differential,
  title={Differential privacy},
  author={Dwork, Cynthia},
  booktitle={International colloquium on automata, languages, and programming},
  pages={1--12},
  year={2006},
  organization={Springer}
}

@inproceedings{dwork2012fairness,
  title={Fairness through awareness},
  author={Dwork, Cynthia and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Zemel, Richard},
  booktitle={Proceedings of the 3rd innovations in theoretical computer science conference},
  pages={214--226},
  year={2012}
}

@article{hardt2016equality,
  title={Equality of opportunity in supervised learning},
  author={Hardt, Moritz and Price, Eric and Srebro, Nati},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}


@inproceedings{mohri2019agnostic,
  title={Agnostic federated learning},
  author={Mohri, Mehryar and Sivek, Gary and Suresh, Ananda Theertha},
  booktitle={International conference on machine learning},
  pages={4615--4625},
  year={2019},
  organization={PMLR}
}

@inproceedings{fukuchi2017differentially,
  title={Differentially private empirical risk minimization with input perturbation},
  author={Fukuchi, Kazuto and Tran, Quang Khai and Sakuma, Jun},
  booktitle={Discovery Science: 20th International Conference, DS 2017, Kyoto, Japan, October 15--17, 2017, Proceedings 20},
  pages={82--90},
  year={2017},
  organization={Springer}
}


@article{wang2020empirical,
  title={Empirical risk minimization in the non-interactive local model of differential privacy},
  author={Wang, Di and Gaboardi, Marco and Smith, Adam and Xu, Jinhui},
  journal={Journal of machine learning research},
  volume={21},
  number={200},
  pages={1--39},
  year={2020}
}

@article{yang2024local,
  title={Local differential privacy and its applications: A comprehensive survey},
  author={Yang, Mengmeng and Guo, Taolin and Zhu, Tianqing and Tjuawinata, Ivan and Zhao, Jun and Lam, Kwok-Yan},
  journal={Computer Standards \& Interfaces},
  volume={89},
  pages={103827},
  year={2024},
  publisher={Elsevier}
}

@article{wang2020comprehensive,
  title={A comprehensive survey on local differential privacy toward data statistics and analysis},
  author={Wang, Teng and Zhang, Xuefeng and Feng, Jingyu and Yang, Xinyu},
  journal={Sensors},
  volume={20},
  number={24},
  pages={7030},
  year={2020},
  publisher={MDPI}
}

@article{chaudhuri2011differentially,
  title={Differentially private empirical risk minimization.},
  author={Chaudhuri, Kamalika and Monteleoni, Claire and Sarwate, Anand D},
  journal={Journal of Machine Learning Research},
  volume={12},
  number={3},
  year={2011}
}

@article{wang2017differentially,
  title={Differentially private empirical risk minimization revisited: Faster and more general},
  author={Wang, Di and Ye, Minwei and Xu, Jinhui},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@inproceedings{wang2019differentially,
  title={Differentially private empirical risk minimization with smooth non-convex loss functions: A non-stationary view},
  author={Wang, Di and Xu, Jinhui},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={1182--1189},
  year={2019}
}

@inproceedings{bassily2021non,
  title={Non-euclidean differentially private stochastic convex optimization},
  author={Bassily, Raef and Guzm{\'a}n, Crist{\'o}bal and Nandi, Anupama},
  booktitle={Conference on Learning Theory},
  pages={474--499},
  year={2021},
  organization={PMLR}
}
@inproceedings{bassily2014private,
  title={Private empirical risk minimization: Efficient algorithms and tight error bounds},
  author={Bassily, Raef and Smith, Adam and Thakurta, Abhradeep},
  booktitle={2014 IEEE 55th annual symposium on foundations of computer science},
  pages={464--473},
  year={2014},
  organization={IEEE}
}

@inproceedings{song2013stochastic,
  title={Stochastic gradient descent with differentially private updates},
  author={Song, Shuang and Chaudhuri, Kamalika and Sarwate, Anand D},
  booktitle={2013 IEEE global conference on signal and information processing},
  pages={245--248},
  year={2013},
  organization={IEEE}
}

@article{lowy2021output,
  title={Output perturbation for differentially private convex optimization with improved population loss bounds, runtimes and applications to private adversarial training},
  author={Lowy, Andrew and Razaviyayn, Meisam},
  journal={arXiv preprint arXiv:2102.04704},
  year={2021}
}

@inproceedings{abadi2016deep,
  title={Deep learning with differential privacy},
  author={Abadi, Martin and Chu, Andy and Goodfellow, Ian and McMahan, H Brendan and Mironov, Ilya and Talwar, Kunal and Zhang, Li},
  booktitle={Proceedings of the 2016 ACM SIGSAC conference on computer and communications security},
  pages={308--318},
  year={2016}
}

@inproceedings{kamiran2010discrimination,
  title={Discrimination aware decision tree learning},
  author={Kamiran, Faisal and Calders, Toon and Pechenizkiy, Mykola},
  booktitle={2010 IEEE international conference on data mining},
  pages={869--874},
  year={2010},
  organization={IEEE}
}

@inproceedings{woodworth2017learning,
  title={Learning non-discriminatory predictors},
  author={Woodworth, Blake and Gunasekar, Suriya and Ohannessian, Mesrob I and Srebro, Nathan},
  booktitle={Conference on Learning Theory},
  pages={1920--1953},
  year={2017},
  organization={PMLR}
}

@inproceedings{iosifidis2019fae,
  title={Fae: A fairness-aware ensemble framework},
  author={Iosifidis, Vasileios and Fetahu, Besnik and Ntoutsi, Eirini},
  booktitle={2019 IEEE international conference on big data (big data)},
  pages={1375--1380},
  year={2019},
  organization={IEEE}
}

@article{chzhen2019leveraging,
  title={Leveraging labeled and unlabeled data for consistent fair binary classification},
  author={Chzhen, Evgenii and Denis, Christophe and Hebiri, Mohamed and Oneto, Luca and Pontil, Massimiliano},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{lohaus2020too,
  title={Too relaxed to be fair},
  author={Lohaus, Michael and Perrot, Michael and Von Luxburg, Ulrike},
  booktitle={International Conference on Machine Learning},
  pages={6360--6369},
  year={2020},
  organization={PMLR}
}

@inproceedings{chai2022fairness,
  title={Fairness with adaptive weights},
  author={Chai, Junyi and Wang, Xiaoqian},
  booktitle={International Conference on Machine Learning},
  pages={2853--2866},
  year={2022},
  organization={PMLR}
}

@article{kamiran2012data,
  title={Data preprocessing techniques for classification without discrimination},
  author={Kamiran, Faisal and Calders, Toon},
  journal={Knowledge and information systems},
  volume={33},
  number={1},
  pages={1--33},
  year={2012},
  publisher={Springer}
}

@inproceedings{feldman2015certifying,
  title={Certifying and removing disparate impact},
  author={Feldman, Michael and Friedler, Sorelle A and Moeller, John and Scheidegger, Carlos and Venkatasubramanian, Suresh},
  booktitle={proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={259--268},
  year={2015}
}

@article{calmon2017optimized,
  title={Optimized pre-processing for discrimination prevention},
  author={Calmon, Flavio and Wei, Dennis and Vinzamuri, Bhanukiran and Natesan Ramamurthy, Karthikeyan and Varshney, Kush R},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{zafar2017fairness,
  title={Fairness beyond disparate treatment \& disparate impact: Learning classification without disparate mistreatment},
  author={Zafar, Muhammad Bilal and Valera, Isabel and Gomez Rodriguez, Manuel and Gummadi, Krishna P},
  booktitle={Proceedings of the 26th international conference on world wide web},
  pages={1171--1180},
  year={2017}
}

@article{donini2018empirical,
  title={Empirical risk minimization under fairness constraints},
  author={Donini, Michele and Oneto, Luca and Ben-David, Shai and Shawe-Taylor, John S and Pontil, Massimiliano},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{wu2019convexity,
  title={On convexity and bounds of fairness-aware classification},
  author={Wu, Yongkai and Zhang, Lu and Wu, Xintao},
  booktitle={The World Wide Web Conference},
  pages={3356--3362},
  year={2019}
}

@article{maheshwari2023fairgrad,
  title={FairGrad: Fairness Aware Gradient Descent},
  author={Maheshwari, Gaurav and Perrot, Micha{\"e}l},
  journal={Transactions on Machine Learning Research Journal},
  year={2023}
}

@article{chzhen2024regression,
  title={Regression under demographic parity constraints via unlabeled post-processing},
  author={Chzhen, Evgenii and Hebiri, Mohamed and Taturyan, Gayane},
  journal={arXiv preprint arXiv:2407.15453},
  year={2024}
}


@inproceedings{pan2023fedmdfg,
  title={Fedmdfg: Federated learning with multi-gradient descent and fair guidance},
  author={Pan, Zibin and Wang, Shuyi and Li, Chi and Wang, Haijin and Tang, Xiaoying and Zhao, Junhua},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={8},
  pages={9364--9371},
  year={2023}
}

@article{huang2024federated,
  title={Federated learning for generalization, robustness, fairness: A survey and benchmark},
  author={Huang, Wenke and Ye, Mang and Shi, Zekun and Wan, Guancheng and Li, He and Du, Bo and Yang, Qiang},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2024},
  publisher={IEEE}
}


@inproceedings{noble2022differentially,
  title={Differentially private federated learning on heterogeneous data},
  author={Noble, Maxence and Bellet, Aur{\'e}lien and Dieuleveut, Aymeric},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={10110--10145},
  year={2022},
  organization={PMLR}
}

@article{fu2024differentially,
  title={Differentially private federated learning: A systematic review},
  author={Fu, Jie and Hong, Yuan and Ling, Xinpeng and Wang, Leixia and Ran, Xun and Sun, Zhiyu and Wang, Wendy Hui and Chen, Zhili and Cao, Yang},
  journal={arXiv preprint arXiv:2405.08299},
  year={2024}
}

@inproceedings{yang2023privatefl,
  title={$\{$PrivateFL$\}$: Accurate, differentially private federated learning via personalized data transformation},
  author={Yang, Yuchen and Hui, Bo and Yuan, Haolin and Gong, Neil and Cao, Yinzhi},
  booktitle={32nd USENIX Security Symposium (USENIX Security 23)},
  pages={1595--1612},
  year={2023}
}

@article{wei2020federated,
  title={Federated learning with differential privacy: Algorithms and performance analysis},
  author={Wei, Kang and Li, Jun and Ding, Ming and Ma, Chuan and Yang, Howard H and Farokhi, Farhad and Jin, Shi and Quek, Tony QS and Poor, H Vincent},
  journal={IEEE transactions on information forensics and security},
  volume={15},
  pages={3454--3469},
  year={2020},
  publisher={IEEE}
}

@inproceedings{iyengar2019towards,
  title={Towards practical differentially private convex optimization},
  author={Iyengar, Roger and Near, Joseph P and Song, Dawn and Thakkar, Om and Thakurta, Abhradeep and Wang, Lun},
  booktitle={2019 IEEE symposium on security and privacy (SP)},
  pages={299--316},
  year={2019},
  organization={IEEE}
}

@article{malekzadeh2021dopamine,
  title={Dopamine: Differentially private federated learning on medical data},
  author={Malekzadeh, Mohammad and Hasircioglu, Burak and Mital, Nitish and Katarya, Kunal and Ozfatura, Mehmet Emre and G{\"u}nd{\"u}z, Deniz},
  journal={arXiv preprint arXiv:2101.11693},
  year={2021}
}

@inproceedings{cheng2022differentially,
  title={Differentially private federated learning with local regularization and sparsification},
  author={Cheng, Anda and Wang, Peisong and Zhang, Xi Sheryl and Cheng, Jian},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10122--10131},
  year={2022}
}

@article{lu2019differentially,
  title={Differentially private asynchronous federated learning for mobile edge computing in urban informatics},
  author={Lu, Yunlong and Huang, Xiaohong and Dai, Yueyue and Maharjan, Sabita and Zhang, Yan},
  journal={IEEE Transactions on Industrial Informatics},
  volume={16},
  number={3},
  pages={2134--2143},
  year={2019},
  publisher={IEEE}
}

@inproceedings{liu2021flame,
  title={Flame: Differentially private federated learning in the shuffle model},
  author={Liu, Ruixuan and Cao, Yang and Chen, Hong and Guo, Ruoyang and Yoshikawa, Masatoshi},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={10},
  pages={8688--8696},
  year={2021}
}
@inproceedings{bonawitz2017practical,
  title={Practical secure aggregation for privacy-preserving machine learning},
  author={Bonawitz, Keith and Ivanov, Vladimir and Kreuter, Ben and Marcedone, Antonio and McMahan, H Brendan and Patel, Sarvar and Ramage, Daniel and Segal, Aaron and Seth, Karn},
  booktitle={proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},
  pages={1175--1191},
  year={2017}
}
@inproceedings{chen2022fundamental,
  title={The fundamental price of secure aggregation in differentially private federated learning},
  author={Chen, Wei-Ning and Choo, Christopher A Choquette and Kairouz, Peter and Suresh, Ananda Theertha},
  booktitle={International Conference on Machine Learning},
  pages={3056--3089},
  year={2022},
  organization={PMLR}
}
@article{geyer2017differentially,
  title={Differentially private federated learning: A client level perspective},
  author={Geyer, Robin C and Klein, Tassilo and Nabi, Moin},
  journal={arXiv preprint arXiv:1712.07557},
  year={2017}
}

@inproceedings{koloskova2023revisiting,
  title={Revisiting Gradient Clipping: Stochastic bias and tight convergence guarantees},
  author={Koloskova, Anastasia and Hendrikx, Hadrien and Stich, Sebastian U},
  booktitle={International Conference on Machine Learning},
  pages={17343--17363},
  year={2023},
  organization={PMLR}
}

@article{andrew2021differentially,
  title={Differentially private learning with adaptive clipping},
  author={Andrew, Galen and Thakkar, Om and McMahan, Brendan and Ramaswamy, Swaroop},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={17455--17466},
  year={2021}
}

@article{shulgin2024convergence,
  title={On the Convergence of DP-SGD with Adaptive Clipping},
  author={Shulgin, Egor and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:2412.19916},
  year={2024}
}
@article{defazio2016simple,
  title={A simple practical accelerated method for finite sums},
  author={Defazio, Aaron},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{cui2021addressing,
  title={Addressing algorithmic disparity and performance inconsistency in federated learning},
  author={Cui, Sen and Pan, Weishen and Liang, Jian and Zhang, Changshui and Wang, Fei},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={26091--26102},
  year={2021}
}

@inproceedings{papadaki2022minimax,
  title={Minimax demographic group fairness in federated learning},
  author={Papadaki, Afroditi and Martinez, Natalia and Bertran, Martin and Sapiro, Guillermo and Rodrigues, Miguel},
  booktitle={Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
  pages={142--159},
  year={2022}
}
@article{chen2023privacy,
  title={Privacy and fairness in Federated learning: on the perspective of Tradeoff},
  author={Chen, Huiqiang and Zhu, Tianqing and Zhang, Tao and Zhou, Wanlei and Yu, Philip S},
  journal={ACM Computing Surveys},
  volume={56},
  number={2},
  pages={1--37},
  year={2023},
  publisher={ACM New York, NY}
}

@inproceedings{cummings2019compatibility,
  title={On the compatibility of privacy and fairness},
  author={Cummings, Rachel and Gupta, Varun and Kimpara, Dhamma and Morgenstern, Jamie},
  booktitle={Adjunct Publication of the 27th Conference on User Modeling, Adaptation and Personalization},
  pages={309--315},
  year={2019}
}

@article{agarwaltrade,
  title={Trade-Offs between Fairness and Privacy in Machine Learning},
  author={Agarwal, Sushant},
  year={2020}
}

@inproceedings{sanyal2022unfair,
  title={How unfair is private learning?},
  author={Sanyal, Amartya and Hu, Yaxi and Yang, Fanny},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={1738--1748},
  year={2022},
  organization={PMLR}
}
@article{shi2023towards,
  title={Towards fairness-aware federated learning},
  author={Shi, Yuxin and Yu, Han and Leung, Cyril},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  year={2023},
  publisher={IEEE}
}
@article{chu2021fedfair,
  title={Fedfair: Training fair models in cross-silo federated learning},
  author={Chu, Lingyang and Wang, Lanjun and Dong, Yanjie and Pei, Jian and Zhou, Zirui and Zhang, Yong},
  journal={arXiv preprint arXiv:2109.05662},
  year={2021}
}
@article{zeng2021improving,
  title={Improving fairness via federated learning},
  author={Zeng, Yuchen and Chen, Hongxu and Lee, Kangwook},
  journal={arXiv preprint arXiv:2110.15545},
  year={2021}
}
@article{abay2020mitigating,
  title={Mitigating bias in federated learning},
  author={Abay, Annie and Zhou, Yi and Baracaldo, Nathalie and Rajamoni, Shashank and Chuba, Ebube and Ludwig, Heiko},
  journal={arXiv preprint arXiv:2012.02447},
  year={2020}
}
@inproceedings{ezzeldin2023fairfed,
  title={Fairfed: Enabling group fairness in federated learning},
  author={Ezzeldin, Yahya H and Yan, Shen and He, Chaoyang and Ferrara, Emilio and Avestimehr, A Salman},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={37},
  number={6},
  pages={7494--7502},
  year={2023}
}

@article{zhang2021unified,
  title={Unified group fairness on federated learning},
  author={Zhang, Fengda and Kuang, Kun and Liu, Yuxuan and Chen, Long and Wu, Chao and Wu, Fei and Lu, Jiaxun and Shao, Yunfeng and Xiao, Jun},
  journal={arXiv preprint arXiv:2111.04986},
  year={2021}
}
@inproceedings{du2021fairness,
  title={Fairness-aware agnostic federated learning},
  author={Du, Wei and Xu, Depeng and Wu, Xintao and Tong, Hanghang},
  booktitle={Proceedings of the 2021 SIAM International Conference on Data Mining (SDM)},
  pages={181--189},
  year={2021},
  organization={SIAM}
}
@article{li2019fair,
  title={Fair resource allocation in federated learning},
  author={Li, Tian and Sanjabi, Maziar and Beirami, Ahmad and Smith, Virginia},
  journal={arXiv preprint arXiv:1905.10497},
  year={2019}
}
@article{maheshwari2022fairgrad,
  title={Fairgrad: Fairness aware gradient descent},
  author={Maheshwari, Gaurav and Perrot, Micha{\"e}l},
  journal={arXiv preprint arXiv:2206.10923},
  year={2022}
}

@article{dwork2014algorithmic,
  title={The algorithmic foundations of differential privacy},
  author={Dwork, Cynthia and Roth, Aaron and others},
  journal={Foundations and Trends{\textregistered} in Theoretical Computer Science},
  volume={9},
  number={3--4},
  pages={211--407},
  year={2014},
  publisher={Now Publishers, Inc.}
}

@article{talwar2015nearly,
  title={Nearly optimal private lasso},
  author={Talwar, Kunal and Guha Thakurta, Abhradeep and Zhang, Li},
  journal={Advances in Neural Information Processing Systems},
  volume={28},
  year={2015}
}

@misc{godel_prize_differential_privacy,
  title        = {Prix Gödel pour la confidentialité différentielle},
  year         = {2017},
  author       = {Cynthia Dwork and Frank McSherry and Kobbi Nissim and Adam Smith},
  note         = {Pour leurs contributions fondamentales à la définition et au développement de la confidentialité différentielle},
  url          = {https://eatcs.org/index.php/component/content/article/1-news/2450-2017-godel-prize}
}

@misc{heartdisease,
  author       = {Janosi, Andras and Steinbrunn, William and Pfisterer, Matthias and Detrano, Robert},
  title        = {{Heart Disease}},
  year         = {1989},
  howpublished = {UCI Machine Learning Repository},
  note         = {{DOI}: https://doi.org/10.24432/C52P4X}
}
@article{flamary2021pot,
  title={Pot: Python optimal transport},
  author={Flamary, R{\'e}mi and Courty, Nicolas and Gramfort, Alexandre and Alaya, Mokhtar Z and Boisbunon, Aur{\'e}lie and Chambon, Stanislas and Chapel, Laetitia and Corenflos, Adrien and Fatras, Kilian and Fournier, Nemo and others},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={78},
  pages={1--8},
  year={2021}
}

@article{azizian2024long,
  title={What is the Long-Run Distribution of SGD? A Large Deviation Analysis},
  author={Azizian, W and Iutzeler, F and Malick, J and Mertikopoulos, P},
  journal={arXiv preprint arXiv:2406.09241},
  year={2024}
}

@inproceedings{gaucher2023fair,
  title={Fair learning with Wasserstein barycenters for non-decomposable performance measures},
  author={Gaucher, Solenne and Schreuder, Nicolas and Chzhen, Evgenii},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2436--2459},
  year={2023},
  organization={PMLR}
}

@article{divol2024demographic,
  title={Demographic parity in regression and classification within the unawareness framework},
  author={Divol, Vincent and Gaucher, Solenne},
  journal={arXiv preprint arXiv:2409.02471},
  year={2024}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{team2025intellect,
  title={INTELLECT-2: A Reasoning Model Trained Through Globally Decentralized Reinforcement Learning},
  author={Team, Prime Intellect and Jaghouar, Sami and Mattern, Justus and Ong, Jack Min and Straube, Jannik and Basra, Manveer and Pazdera, Aaron and Thaman, Kushal and Di Ferrante, Matthew and Gabriel, Felix and others},
  journal={arXiv preprint arXiv:2505.07291},
  year={2025}
}

@article{ngan2003multivariate,
  title={Multivariate analysis of factors associated with umbilical arterial pH and standard base excess after Caesarean section under spinal anaesthesia},
  author={Ngan Kee, WD and Lee, Anna},
  journal={Anaesthesia},
  volume={58},
  number={2},
  pages={125--130},
  year={2003},
  publisher={Wiley Online Library}
}

@article{bagdasaryan2019differential,
  title={Differential privacy has disparate impact on model accuracy},
  author={Bagdasaryan, Eugene and Poursaeed, Omid and Shmatikov, Vitaly},
  journal={NeurIPS},
  year={2019}
}


@article{khaled2022faster,
  title={Faster federated optimization under second-order similarity},
  author={Khaled, Ahmed and Jin, Chi},
  journal={arXiv preprint arXiv:2209.02257},
  year={2022}
}